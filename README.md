# ğŸ“š LLM-RAG-Document-QA

A **Retrieval-Augmented Generation (RAG)** system built from scratch that answers user questions strictly using provided documents, with **grounding, source attribution, and evaluation metrics** to reduce hallucinations.

---

## ğŸš€ Features

- ğŸ” Semantic document retrieval using dense embeddings
- ğŸ§  LLM-based answer generation (Flan-T5)
- ğŸ“Œ Source attribution for transparency
- ğŸ§ª Evaluation metrics for grounding & faithfulness
- âš™ï¸ Modular, extensible architecture
- ğŸ—ï¸ Built without LangChain (core concepts implemented manually)

---

## ğŸ§  What is RAG?

Retrieval-Augmented Generation (RAG) combines:
- **Information Retrieval** â†’ fetch relevant knowledge
- **Language Models** â†’ reason and generate answers

This ensures answers are **grounded in documents**, not hallucinated.

---

## ğŸ—ï¸ System Architecture

User Question
â”‚
â–¼
Query Embedding
â”‚
â–¼
Vector Similarity Search
â”‚
â–¼
Top-K Relevant Chunks
â”‚
â–¼
Context + Question Prompt
â”‚
â–¼
LLM (Flan-T5)
â”‚
â–¼
Answer + Sources + Evaluation


---

## ğŸ§© Pipeline Breakdown

### 1ï¸âƒ£ Document Ingestion
- Loads text files from `data/documents/`
- Preserves source metadata (filename)

### 2ï¸âƒ£ Chunking
- Documents are split into overlapping chunks
- Each chunk retains its source

### 3ï¸âƒ£ Embedding
- Uses `all-MiniLM-L6-v2`
- Chunks and queries are embedded into the same vector space

### 4ï¸âƒ£ Retrieval
- Cosine similarity used to rank chunks
- Top-K chunks retrieved
- Similarity threshold applied to avoid weak matches

### 5ï¸âƒ£ Prompt Construction
- Retrieved chunks are passed as context
- Original user question is included to guide reasoning

### 6ï¸âƒ£ Generation
- LLM generates answer **strictly from context**
- If context is insufficient â†’ abstains

### 7ï¸âƒ£ Source Attribution
- Displays which document chunks were used
- Improves trust and explainability

### 8ï¸âƒ£ Evaluation
- **Recall@K** â†’ checks retrieval quality
- **Context Coverage** â†’ measures grounding
- **Faithfulness Check** â†’ detects hallucination risk

---

## ğŸ“Š Evaluation Metrics

| Metric | Description |
|------|------------|
| Recall@K | Did we retrieve relevant chunks? |
| Context Coverage | How much answer overlaps with context |
| Faithfulness | Binary grounding decision |

---

## ğŸ“ Project Structure
LLM-RAG-Document-QA/
â”‚
â”œâ”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ documents/
â”‚
â”œâ”€â”€ ingestion/
â”‚ â”œâ”€â”€ load_documents.py
â”‚ â””â”€â”€ chunking.py
â”‚
â”œâ”€â”€ embeddings/
â”‚ â”œâ”€â”€ embedding_model.py
â”‚ â””â”€â”€ generate_embeddings.py
â”‚
â”œâ”€â”€ retrieval/
â”‚ â””â”€â”€ similarity.py
â”‚
â”œâ”€â”€ llm/
â”‚ â”œâ”€â”€ llm_model.py
â”‚ â”œâ”€â”€ prompt.py
â”‚ â””â”€â”€ inference.py
â”‚
â”œâ”€â”€ evaluation/
â”‚ â”œâ”€â”€ retrieval_metrics.py
â”‚ â”œâ”€â”€ context_coverage.py
â”‚ â””â”€â”€ faithfulness.py
â”‚
â””â”€â”€ README.md

---

## â–¶ï¸ How to Run

```bash
pip install -r requirements.txt
python app.py

## Add your documents inside:

data/documents/

ğŸ§  Key Learnings

Why retrieval alone is insufficient

How prompt + context work together

Importance of similarity thresholds

How to detect hallucinations

Real-world RAG evaluation strategies

ğŸ”® Future Improvements

PDF ingestion

Streamlit UI

Vector database (FAISS)

Hugging Face deployment

Conversational memory

ğŸ‘¤ Author

Anshu Pandey
Machine Learning & Deep Learning Practitioner
Focused on building systems from first principles
